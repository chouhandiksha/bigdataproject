{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyse LA Compare Part Time Work Percentage For Wealthiest And Poorest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chouhandiksha/bigdataproject/blob/main/notebooks/Analyse%20LA%20Compare%20Part%20Time%20Work%20Percentage%20For%20Wealthiest%20And%20Poorest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vnc5foT5YFx"
      },
      "source": [
        "**Spark SQL Documentation:** \n",
        "https://spark.apache.org/docs/2.2.0/sql-programming-guide.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc_t3BVRPlNO"
      },
      "source": [
        "# Analyse LA Compare Part Time Work Percentage For Wealthiest And Poorest\n",
        "\n",
        "*Instructions:*\n",
        "\n",
        "1. Execute the first code cell.\n",
        "2. There will be a link to follow in order to authorize the google account for drive. Go to that link.\n",
        "3. A code to authorize the google account will be generated. Copy the code generated.\n",
        "4. Go back to the cell where the process of mounting the drive is running. Paste the generated code from step 3 to the text box in the cell and press enter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK0v9vBUPkT4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tQ_ZhBrPjcj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXJ-cpgT3moz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2cc863-482f-40a2-f4d2-275547b60f22"
      },
      "source": [
        "# add time information at the end of every cell\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (56.0.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "time: 2.06 ms (started: 2021-05-03 19:22:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DggpqrsrscGi",
        "outputId": "0e747e3e-2cbb-4172-c36d-c88949fb1911"
      },
      "source": [
        "# Install required dependancies\n",
        "!pip install pyspark\n",
        "!apt update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "76 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "openjdk-8-jdk-headless is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
            "time: 9.01 s (started: 2021-05-03 19:22:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppkG73kRsei0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b986a0-cd33-448c-d557-5645fb9af718"
      },
      "source": [
        "# Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 111 ms (started: 2021-05-03 19:22:57 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYm9-j_fflal",
        "outputId": "a4e765c3-5c6f-4caa-80d6-4aa07b0c467c"
      },
      "source": [
        "import altair as alt\n",
        "alt.data_transformers.disable_max_rows()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataTransformerRegistry.enable('default')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "text": [
            "time: 165 ms (started: 2021-05-03 19:22:57 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oe1ksN5skMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3da695c-b4e1-46c4-ad43-bf5c32d3b574"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.84 s (started: 2021-05-03 19:22:57 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdPF-0xIrDm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f4565f-8e81-400b-d262-a1b3441a0822"
      },
      "source": [
        "#sc.stop()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.81 ms (started: 2021-05-03 19:23:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xveMbFydr0_x",
        "outputId": "82bd3b92-4b4a-461e-a8b9-f82a2b8d4063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount drive with data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 2.4 ms (started: 2021-05-03 19:23:31 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grN2uNcFvloa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "badef61d-d098-4dc4-e3ff-2e048315c422"
      },
      "source": [
        "# Set path to data folder\n",
        "path = Path('drive/MyDrive/big-data-project/data/clean-data')\n",
        "city = 'la'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.61 ms (started: 2021-05-03 19:23:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "BvCrFmU2tGXY",
        "outputId": "0979b274-34a8-422e-9c5d-16ee73395930"
      },
      "source": [
        "# Read data into dataframe\n",
        "df_soc = spark.read.format('csv').option('header','true').option('quote',\"\\\"\").option('escape',\"\\\"\").load(str(path/city/'social/2020/*.csv'))\n",
        "df_soc.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d87650b42b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read data into dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_soc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quote'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'escape'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'social/2020/*.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_soc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/content/drive/MyDrive/big-data-project/data/clean-data/la/social/2020/*.csv"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 1.58 s (started: 2021-05-03 19:23:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh747sqcHi4-"
      },
      "source": [
        "df_soc.createOrReplaceTempView('clean_la')\n",
        "df_soc = spark.sql('SELECT cbg, date_range_start as date, device_count, part_time_work_behavior_devices FROM clean_la WHERE device_count > 5')\n",
        "df_soc.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVhrn2-Rp_O"
      },
      "source": [
        "df_soc = df_soc.withColumn(\"date\",\n",
        "    df_soc['date'].substr(0, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ryRoACoJMPZ"
      },
      "source": [
        "df_soc.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL4qIhZu7JKC"
      },
      "source": [
        "# Add completely home percentage column\n",
        "df_soc = df_soc.withColumn('part_time_work_percentage', (df_soc['part_time_work_behavior_devices']/df_soc['device_count']) * 100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAUIODseCoSg"
      },
      "source": [
        "#Create temp view\n",
        "df_soc.createOrReplaceTempView('mobility')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj4xc1gTpm2X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Demographic data**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SVVsXtuzqRf"
      },
      "source": [
        "# Read poverty data\n",
        "# Read data into RDD\n",
        "df_demographic = spark.read.format('csv').option('header','true').option('quote',\"\\\"\").option('escape',\"\\\"\").load(str(path/city/'la.csv'))\n",
        "df_demographic.createOrReplaceTempView('demographic')\n",
        "df_demographic.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff9bk8_6qBQ2"
      },
      "source": [
        "df_mob_demo = spark.sql('SELECT mobility.*, demographic.poverty_percentage from mobility INNER JOIN demographic ON mobility.cbg = demographic.cbg')\n",
        "df_mob_demo.createOrReplaceTempView('demographic_mobility')\n",
        "df_mob_demo.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vFzCEtNukZy"
      },
      "source": [
        "# DIVIDING THE PEOPLE TOP 20 PERCENT AND BOTTOM 20 PERCENT\n",
        "\n",
        "df_mob_demo_high_class =  spark.sql('SELECT * FROM demographic_mobility WHERE poverty_percentage < 20')\n",
        "grouped_df_mob_demo_high_class = df_mob_demo_high_class.groupBy(\"date\").mean(\"part_time_work_percentage\").withColumnRenamed('avg(part_time_work_percentage)','part_time_work_percentage')\n",
        "grouped_df_mob_demo_high_class.createOrReplaceTempView('mob_demo_high_class')\n",
        "\n",
        "\n",
        "df_mob_demo_low_class =  spark.sql('SELECT * FROM demographic_mobility WHERE poverty_percentage > 80')\n",
        "grouped_df_mob_demo_low_class = df_mob_demo_low_class.groupBy(\"date\").mean(\"part_time_work_percentage\").withColumnRenamed('avg(part_time_work_percentage)','part_time_work_percentage')\n",
        "grouped_df_mob_demo_low_class.createOrReplaceTempView('mob_demo_low_class')\n",
        "\n",
        "grouped_df_mob_demo_combined = spark.sql(\"\"\"\n",
        "\n",
        "SELECT h.date,h.part_time_work_percentage as top20_perc,\n",
        "l.part_time_work_percentage as bottom20_perc  \n",
        "FROM mob_demo_high_class h INNER JOIN mob_demo_low_class l ON h.date = l.date\n",
        "\n",
        "\"\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow6mFwCFoc4r"
      },
      "source": [
        "**Load 2019 stats**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBe00iTKobbO"
      },
      "source": [
        "filename = '{}_social_summary_2019.csv'.format(city)\n",
        "stat_2019 = spark.read.format('csv').option('header','true').option('quote',\"\\\"\").option('escape',\"\\\"\").load(str(path/city/filename))\n",
        "stat_2019.show()\n",
        "mean_2019 = stat_2019.collect()[1][6]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbZKBBrlsymR"
      },
      "source": [
        "# calculate deviation form mean\n",
        "grouped_df_mob_demo_combined= grouped_df_mob_demo_combined.withColumn(\"top20_deviation\",\n",
        "    grouped_df_mob_demo_combined['top20_perc'] - mean_2019)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1v1M4wSwmbV"
      },
      "source": [
        "grouped_df_mob_demo_combined = grouped_df_mob_demo_combined.withColumn(\"bottom20_deviation\",\n",
        "    grouped_df_mob_demo_combined['bottom20_perc'] - mean_2019)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxSLoJSmYuj8"
      },
      "source": [
        "\n",
        "**Visualizations** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4CaYZVO43kY"
      },
      "source": [
        "# create altair library theme \n",
        "\n",
        "def my_theme():\n",
        "  return {\n",
        "    'config': {\n",
        "      'view': {'continuousHeight': 300, 'continuousWidth': 400},  # from the default theme\n",
        "      'range': {'category': {'scheme': ['#FF4500','#a0aab4','#4E79A7']}}\n",
        "    }\n",
        "  }\n",
        "alt.themes.register('my_theme', my_theme)\n",
        "alt.themes.enable('my_theme')\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KpTm73-BpiA"
      },
      "source": [
        "def create_chart(df,mon) :\n",
        "  chart = alt.Chart(df).transform_fold(\n",
        "    fold=['Bottom 20 % Deviation', 'Top 20 % Deviation'],\n",
        "    as_ = ['Poverty %','part_time_value']\n",
        "    \n",
        "    ).mark_line().encode(\n",
        "      x= alt.X('date:T', title = mon),\n",
        "      y= alt.Y('part_time_value:Q', title = 'Part Time Work %'),\n",
        "      color='Poverty %:N'\n",
        "    ).properties(width = 1000)\n",
        "\n",
        "  rule = alt.Chart(pd.DataFrame({'Mean 2019':[0]})).mark_rule(color='#757575',strokeDash=[5,3], size=2).encode(\n",
        "    y='Mean 2019',\n",
        "    size=alt.value(2),\n",
        "    )\n",
        "  \n",
        "  text = alt.Chart({'values':[{ 'y': 1}]}).mark_text(\n",
        "    text='Mean 2019', angle=0\n",
        "    ).encode(\n",
        "      y=alt.Y('y:Q'),opacity=alt.value(0.4)\n",
        "    )\n",
        "\n",
        "  return  chart + rule + text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9AleyUlCeuI"
      },
      "source": [
        "def apply_date_filter(df,start_date,end_date) :\n",
        "  mask = (df['date'] > start_date) & (df['date'] <= end_date)\n",
        "  dfX = df.loc[mask]\n",
        "  return dfX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4EHlNdfSVal"
      },
      "source": [
        "# create pandas dataframe for visualizations\n",
        "df = grouped_df_mob_demo_combined.toPandas()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtFPRkkEZtzL"
      },
      "source": [
        "df = df.rename(columns={'top20_perc': 'Top 20 %', 'bottom20_perc': 'Bottom 20 %','top20_deviation': 'Top 20 % Deviation', 'bottom20_deviation': 'Bottom 20 % Deviation'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTTAkF1Iwesw"
      },
      "source": [
        "# analysis for the entire year on monthly basis\n",
        "df_str = df.copy(deep=True) #make a deep copy\n",
        "\n",
        "df_str['date'] = pd.to_datetime(df_str['date'],utc= True) # extract the months\n",
        "\n",
        "df_str = df_str.groupby([df_str['date']]).mean().rolling(10).mean()[0:] #find the mean for the days and roll up for every 10 days\n",
        "\n",
        "chart = alt.Chart(df_str.reset_index()).transform_fold(\n",
        "    fold=['Bottom 20 %', 'Top 20 %'],\n",
        "    as_ = ['Poverty %','part_time_value']\n",
        "    \n",
        "    ).mark_line().encode(\n",
        "      x='date:T',\n",
        "      y= alt.Y('part_time_value:Q', title = 'Part Time %'), color='Poverty %:N'\n",
        "    ).properties(width = 1000)\n",
        "chart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owhSJQqe7rVM"
      },
      "source": [
        "#Conversion of datetime format\n",
        "df['date'] = pd.to_datetime(df['date'],utc= True)\n",
        "#df['date'] = [datetime.datetime.date(d) for d in df['date']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCVL0_NiBLU0"
      },
      "source": [
        "Filtering based on important dates\n",
        "\n",
        "\n",
        "\n",
        "*   Thursday, March 19, 2020: Statewide Stay-at-Home Order Issued\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gelkUE5NBJps"
      },
      "source": [
        "start_date = '2020-3-16'\n",
        "end_date = '2020-4-9'\n",
        "df1 = apply_date_filter(df,start_date,end_date)\n",
        "chart = create_chart(df1,'March-April')\n",
        "chart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY48F9-7gp2q"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   August. 7, 2020: LA County Exceeds 200,000 Coronavirus Cases\n",
        "*   August, 12, 2020: LA County Crosses 'Tragic Milestone' Of 5,000 Coronavirus Deaths \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DhDPv1GfRhR"
      },
      "source": [
        "start_date = '2020-8-5'\n",
        "end_date = '2020-8-21'\n",
        "df2 = apply_date_filter(df,start_date,end_date)\n",
        "chart = create_chart(df2,'August')\n",
        "chart\n",
        "#df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxC6dH7YiWxd"
      },
      "source": [
        "*   Oct. 14, 2020: LA County Sees Rise In Workplace Outbreaks As Infection Rate Creeps Upward\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTaOPmN5fRmL"
      },
      "source": [
        "start_date = '2020-10-12'\n",
        "end_date = '2020-10-24'\n",
        "df3 = apply_date_filter(df,start_date,end_date)\n",
        "chart = create_chart(df3,'October')\n",
        "chart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1uLmyxVi6Zo"
      },
      "source": [
        "Dec. 16, 2020:\n",
        "LA County COVID-19 Deaths Hit New Record\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ29_JeZfRqz"
      },
      "source": [
        "start_date = '2020-12-15'\n",
        "end_date = '2020-12-31'\n",
        "df4 = apply_date_filter(df,start_date,end_date)\n",
        "chart = create_chart(df4,'December')\n",
        "chart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuiHxms2fRtH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}